# Noah Final Self Assessment

My responsibilities were focused around the sourcing and processing of data, as well as implementing various empirical nutrition recommendation algorithms. This was uniquely foundational to the project as a whole because everything depended on having good data and processes underlying the data that provide valuable information. The two primary sources we used were the USDA FoodData Central datasets, and the Institute of Medicine’s Recommended Dietary Intake and Upper Limit guidelines. Implementing these datasets involved reviewing their licensing terms, accessing the data through CSV downloads or web scraping, and creating pipelines in Python which parse and integrate the data to make relevant recommendations and provide nutrient progress data structure. One aspect of this work that I was particularly proud of was that I even went the extra mile and used a generative large language model to do some data entry tasks that would’ve taken upwards of 30 to 40 hours to do on my own. This included estimated the popularity level of over 5,000 foods, as well as coming up with some emojis to represent the contents of those foods. This allowed us to surface only the most common and popularly accepted foods as recommendations. Associating the 5,000 foods with emojis made use of the expressive emoji icon sets built into web browsers so that the foods would be accompanied with recognizable and appealing icons.

Working on a team with talents in different aspects of the stack was also a good opportunity for practicing  effective and productive communication regarding how aspects of our work would interface with each other. We often settled on defining REST API specifications and passing them back and forth, asking about the presence of particular fields. Then one a specification was provided, it came down to settling on an efficient implementation and testing it appropriately.

I would say in summary, I did my fair share of work along with equal contributions from the rest of the team.
